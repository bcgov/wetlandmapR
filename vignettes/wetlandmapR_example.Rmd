---
title: "wetlandmapR Example"
output: rmarkdown::html_vignette
author: "Deepa Filatow, Gillian Harvey, Hunter Gleason"
vignette: > 
  %\VignetteIndexEntry{wetlandmapR Example}
  %\VignetteEngine{knitr::rmarkdown}
  %\usepackage[utf8]{inputenc}
---
  
  
  The following vignette demonstrates the use of the [wetlandmapR](https://github.com/bcgov/wetlandmapR) package to classify wetlands using terrain derivatives and external inputs such as satellite imagery using example data provided with the package. This document is written to serve as a reference for performing similar classification in any area of interest. 
  
  ## Using the wetlandmapr Docker ...
  
  A docker image based on the [**rocker/geospatial:3.6.3**](https://hub.docker.com/r/rocker/geospatial) image has been assembled for running the [wetlandmapR package](https://github.com/bcgov/wetlandmapR) package. Assuming a local installation of Docker, the [huntgdok/wetlandmapr:latest](https://hub.docker.com/repository/docker/huntgdok/geospat) image can be downloaded by passing the command: 
  
  ```{bash eval=FALSE}
  docker pull huntgdok/wetlandmapr:latest
  ```
  once the image is in place, it can be run using the following Docker command
  
  ```{bash eval=FALSE}
  docker run -e PASSWORD=APassword -e ROOT=TRUE -p 8787:8787 --rm huntgdok/wetlandmapr:latest
  ```
  
  where *APassword* is any password you want. To use with sudo privileges, add *-e ROOT=TRUE* to call. To view the running docker, go to the local URL [localhost](http://localhost:8787) *http://localhost:8787* in your internet browser. When prompted for a username and password, supply *rstudio* as a username, and the password that you set with *docker run*. You should then have a R-Studio session running with all the R and third party dependencies required for running the [**wetlandmapR**](https://github.com/bcgov/wetlandmapR) package. If the user is calculating upstream basin stats, they must first install GRASS-GIS addon *r.stream.extract* into the container. Alternatively, the package can be run locally assuming dependencies are in place. 
  
  ## Load R package dependencies ... 
  
```{r message=FALSE, warning=FALSE}
library(wetlandmapR)
library(rgeos)
library(rgdal)
library(tidyverse)
library(bcmaps)
library(raster)
library(sf)
library(sp)
library(RColorBrewer)
library(doParallel)
library(RStoolbox)
```


## Raster data set-up ... 

The following lines of code define an output directory for the terrain derivatives, load in an example digital elevation model (DEM) from the [wetlandmapR package](https://github.com/bcgov/wetlandmapR), and calls the ***wetlandmapR::create_dem_products*** function to generate terrain derivatives using [SAGA-GIS](http://www.saga-gis.org/) and [RSAGA](https://CRAN.R-project.org/package=RSAGA). These terrain derivatives will be used to predict the wetland classes. All of the terrain outputs including a Sentinel-2 Band 4 raster are converted to a raster stack by calling the ***wetlandmapR::stack_raster*** function. The resulting raster stack is plotted below. As a pre-processing step, ***wetlandmapR::create_dem_products*** first hydrologically conditions the DEM by filling any sinks, a binary sinks layer is output under the name *SINKS.sgrd*. Optionally, if a stream vector is provided it may be burned into the DEM by a distance defined by the user. 

```{r fig.width=6, fig.height=6, message=FALSE, warning=FALSE, results = FALSE, fig.cap="Raster stack of SAGA terrain derivatives and Sentinel-2 band 4 image."}
# Set a random seed 
set.seed(42)

#Specify a output directory, we'll use the temporary directory for this example
out_dir<-paste(tempdir(),"/wetlandmapR_expl",sep="")
dir.create(out_dir)

#Load a example digital elevation model DEM from wetlandmapR package 
target_dem <- system.file('extdata','DEM.tif',package = 'wetlandmapR')

#Load freshwater atlas stream data from wetlandmapR package
streams <- system.file('extdata','streams.shp',package = 'wetlandmapR')

#Create SAGA elevation derivatives using the wetlandmapR 'create_dem_products' function, burn FWA streams into DEM by 5 m ...
create_dem_products(dem=target_dem,stream_vec = streams, burn_val=5, outdir=out_dir)

#Get list of SAGA terrain derivatives within the output directory 
raster_list <- list.files(out_dir, "sdat$", full.names = TRUE)

#Drop the DEM w/ sinks from list
raster_list<-raster_list[!raster_list %in% c(file.path(out_dir,'ELEV_NoSink.sdat'),file.path(out_dir,'ASPECT.sdat'))]

#E.g., Add external Sentinel-2 Band 4 data to the list of raster inputs from wetlandmapR package 
raster_list<-append(raster_list,system.file("extdata", "B4_SENT2.tif", package = "wetlandmapR"))

#Stack all raster inputs using the wetlandmapR 'stack_raster' function, passing 'raster_list' as input, output a raster Look-Up-Table 'rastLUT' CSV 
raster_stack <- stack_rasters(rasters = raster_list, target_raster = target_dem, outdir = out_dir,rastLUTfn = file.path(out_dir,'rastLUT.csv'), aligned=FALSE)

#Plot the new stack of raster objects (input layers)
plot(raster_stack)

```



## Attribute raster values to training points ...

This chunck reads in example training points from the [wetlandmapR](https://github.com/bcgov/wetlandmapR) package as a *sp* object. In addition, biogeoclimatic zones (BEC) are loaded internally using the [bcmaps](https://github.com/bcgov/bcmaps) package. Using the raster stack plotted above as input, the ***wetlandmapR::grid_values_at_sp*** function attributes the intersecting raster values to the training points grouped by the AOI polygons, in this case BEC zones are used as an example. The results are written to the output directory as a CSV *"train_pnts_attributed.csv"*.


```{r fig.width=6, fig.height=6, message=FALSE, warning=FALSE, results=FALSE, fig.cap="Sample points and BEC-ZONE AOI polygons."}
#Load training data as sp  
training_points<-st_read(system.file('extdata', 'TrainingPoints.shp', package = 'wetlandmapR'))

#Load BEC zones from bcmaps as AOIs
aoi_polys<-bec(ask=F) %>% st_crop(training_points)

#Plot AOIs and training points
ggplot()+geom_sf(data=aoi_polys,aes(fill=ZONE))+
  geom_sf(data=training_points)

#Convert aoi_polys to sp
aoi_polys<-as_Spatial(aoi_polys)


#Assign URL to output CSV
attributed_csv <- file.path(out_dir,"train_pnts_attributed.csv")

#Attribute training points with intersecting input raster values grouped by provided AOI, write results to CSV. 
grid_values_at_sp(x=raster_stack,
                  y=training_points,
                  filename = attributed_csv,
                  aoi = aoi_polys)


```

##  Setup predictor list and raster LUT ...

Read in the *rastLUT.csv* file which was output by ***wetlandmapR::stack_rasters***, the first column of this CSV contains the file path to each input raster layer, while the second column indicates the name of the layer, and the third column indicates the band index. Here we get a list of the raster layer names from the *rastLUT* table, and create a new directory for our model outputs.

```{r message=FALSE, warning=FALSE}
#Read in rastLUT table as data.frame 
rastLUT <- read.csv(file.path(out_dir,'rastLUT.csv'),
                    header = FALSE,
                    stringsAsFactors = FALSE)

#View rastLUT table 
rastLUT

#Get the list of input predictor names (2nd column)
predList <- rastLUT[,2]


#Create an output directory within 'out_dir' directory
dir.create(file.path(out_dir,"output"))

```


## Run model and diagnostics ...

Below we build a random forest wetland classification model by calling the ***wetlandmapR::wetland_model*** function using the training data that we attributed with the input raster layers above. We declare the response field to be the "T_W_Class" field, and set *response.type* as categorical. The "OBJECTID" is defined as identifying unique observations. We specify that we want to use the "BGC_ZONE" column to identify separate AOIs. The *responce.target* parameter is for subsetting the training dataset, in this case we use all wetland categories. We also define the "SINKS" column (input) to be a factor variable. The results include a list containing *model.build* objects output from the [ModelMap](https://cran.r-project.org/web/packages/ModelMap/index.html) package for each AOI. Model outputs will be output to the *model.folder* directory, in this case "output". Because the modeling process in random, a seed it set for reproducibility. 

```{r message=FALSE, warning=FALSE}
#Fit a random forest model 
model.out <- wetland_model(qdatafn = attributed_csv,
                           model.type = "RF",
                           model.folder = file.path(out_dir,"output"),
                           unique.rowname = "OBJECTID",
                           predList = predList,
                           predFactor = c('SINKS'),
                           response.name = "T_W_Class",
                           response.type = "categorical",
                           seed = 42,
                           response.target = as.vector(unique(training_points$T_W_Class)),
                           aoi.col = "BGC_ZONE")
```


## Create map(s) from model ...

Finally we call the ***wetlandmapR::wetland_map*** function which generates raster prediction surfaces using the model outputs from ***wetlandmapR::wetland_model***, i.e., *model.out*. We point the function to the output directory assigned to *wetland_model* above. We also pass the *rastLUT* data frame, and BEC AOI SpatialPolygons, the AOI column is defined as the *ZONE* column. 

```{r warning=FALSE, message=FALSE, results=FALSE}
#Map random forest results 
wetland_map(model.out = model.out,
            model.folder = file.path(out_dir,"output"),
            rastLUTfn = rastLUT,
            aoi = aoi_polys,
            aoi.col = "ZONE")
```


## Plot map results

Plot the output classified ERDAS images by AOI ...

```{r fig.width=6, fig.height=6, warning=FALSE, message=FALSE, fig.cap="Mapped Classification Results by AOI"}
#Get .img file paths from temporary directory 
SBS.dir<-list.files(paste(tempdir(),'/wetlandmapR_expl/output/',sep=''),pattern = "SBS")
ESSF.dir<-list.files(paste(tempdir(),'/wetlandmapR_expl/output/',sep=''),pattern = "ESSF")
SBS.img<-paste(SBS.dir,'_map.img',sep='')
ESSF.img<-paste(ESSF.dir,'_map.img',sep='')
SBS.key<-paste(SBS.dir,'_map_key.csv',sep='')
ESSF.key<-paste(ESSF.dir,'_map_key.csv',sep='')

#Plot map results for each AOI
ggR(img=raster(paste(tempdir(),'/wetlandmapR_expl/output/',SBS.dir,'/',SBS.img,sep='')),forceCat = T,geom_raster = T)+labs(fill = "SBS Class")
SBS_key<-read.csv(paste(tempdir(),'/wetlandmapR_expl/output/',SBS.dir,'/',SBS.key,sep=''))
SBS_key
ggR(img=raster(paste(tempdir(),'/wetlandmapR_expl/output/',ESSF.dir,'/',ESSF.img,sep='')),forceCat = T,geom_raster = T)+labs(fill = "ESSF Class")
ESSF_key<-read.csv(paste(tempdir(),'/wetlandmapR_expl/output/',ESSF.dir,'/',ESSF.key,sep=''))
ESSF_key
```


## Attribute upstream basin stats ...

Optionally, after mapping has been completed, upstream basin attributes can be attributed to any point within the study area using ***wetlandmapR::upstream_basin_stats***.

### Set up the GRASS-GIS environment:

First we set up a [**GRASS-GIS**](https://grass.osgeo.org/) environment using the [**rgrass7**](https://cran.r-project.org/web/packages/rgrass7/index.html) package. This is done by calling ***wetlandmapR::set_grass_env***. This function requires that the path the [**GRASS-GIS**](https://grass.osgeo.org/) binaries be provided, in addition to a list of *raster* objects to be summarized, such as those output above, and associated vector of raster layer names.

```{r warning=FALSE, message=FALSE, results=FALSE}
#!!Change to local GRASS-GIS installation if not using Docker image!! 
gisbase<-'/usr/lib/grass76/'

#Get list of raster layers and names 
lyr_lst<-list()
lyr_names<-c()
for(lyr in  c(1:dim(raster_stack)[3]))
{
  lyr_lst[[lyr]]<-raster(rastLUT[lyr,1])
  lyr_names[lyr]<-rastLUT[lyr,2]
}

#Write the raster objects to a GRASS-GIS environment, derive streams and create GRASS DEM derivatives 'r.watershed' 
set_grass_env(gisbase=gisbase,
              DEM=raster(target_dem),
              lyr_list=lyr_lst,
              lyr_names=lyr_names,
              acc_thresh = 1000)
```



### Polygonize wetland classification map ...

In this chunk we polygonize the resulting wetland classification map for the SBS BEC Zone generated by ***wetlandmapR::wetland_map*** using the ***wetlandmapR::raster_to_clean_polygon*** function. We then identify the lowest point for each continuous wetland complex to use as a 
pour point for calculating upstream basin statistics. 

```{r fig.width=6, fig.height=6, message=FALSE, warning=FALSE, fig.cap="Mapped Classification Results by AOI as simplified polygons"}

#Load the wetland classification map for the SBS BEC Zone as raster object
SBS_classified <- raster(paste(tempdir(),'/wetlandmapR_expl/output/',SBS.dir,'/',SBS.img,sep=''))

#Polygonize wetland classification map 
SBS_Class_ply <- raster_to_clean_polygon(SBS_classified,2500,2500,T,"chaikin")

#Plot polygon wetland classification for SBS BEC Zone
ggplot()+
  geom_sf(data = SBS_Class_ply,aes(fill=as.factor(class)))+
  scale_color_brewer(palette = "Spectral")+
  labs(fill = "SBS Class")

#Load the digital elevation model as raster object 
dem<-raster(rastLUT[rastLUT[,2]=='ELEV',1])

#A function for finding the lowest elevation within an area of interest
get_low_pnt<-function(dem,poly)
{
  if(class(dem)==class(raster()))
  {
    dem <- stars::st_as_stars(dem)
  }
  
  masked <- as.data.frame(dem[poly])
  
  masked <- masked[complete.cases(masked),]
  
  xy<-as.vector(masked[which.min(masked[,3]),c('x','y')])
  
  return(xy)
}

#Initilize an empty coordinates vector 
low_pnts <- c()

#Populate coordinated vector with coordinates of lowest elevation pixel within each wetland polygon 
for(i in 1:nrow(SBS_Class_ply)){
  low_pnts<-rbind(low_pnts,get_low_pnt(dem,st_geometry(SBS_Class_ply[i,])))
}
```




### Calculate upstream basin statistics ...

Below we use the *X* and *Y* pour point coordinates of each wetland polygon, representing the lowest elevation location, and attribute a unique identifier field *UID*. We then compute the mean and standard deviation of upstream elevation and topographic wetness for each pour point using the ***wetlandmapR::run_basin_stats*** function as an example of computing upstream basin statistics for a point. 

```{r fig.width=6, fig.height=6, message=FALSE, warning=FALSE, fig.cap="Mapped Classification Results by AOI as simplified polygons, with the standard devation of upstream topographic wetness for each polygons low elevation pour point."}
#Set a random seed
set.seed(42)

#Create a data frame of pour points for purpose of example 
pour_pnts<-as.data.frame(low_pnts)
pour_pnts$UID<-c(1:nrow(pour_pnts))
colnames(pour_pnts)<-c('X','Y','UID')

#View pour point table 
head(pour_pnts)

#Set to number of cores minus 1 
cores<-parallel::detectCores()-1

#For the random pour points calculate upstream basin mean and standard deviation for elevation and topographic wetness.
basin_stats<-run_basin_stats(pour_pnts = pour_pnts,
                             covar_rast = c('ELEV','TOPOWET','ELEV','TOPOWET'),
                             stat_vect = c('MEAN','MEAN','STDDEV','STDDEV'),
                             procs = cores)

#View upstream basin statistics 
head(basin_stats)

#Merge the upstream statistics with pour point coordinates by unique ID field (UID) 
pour_pnts <- merge(pour_pnts,basin_stats,by="UID")

#Overlay wetland low elevation pour points sized by the standard deviation of upstream topographic wetness
#over the original wetland polygons.
ggplot()+
  geom_sf(data = SBS_Class_ply,aes(fill=as.factor(class)))+
  scale_color_brewer(palette = "Spectral")+
  geom_point(data=pour_pnts,aes(x=X,y=Y,size=TOPOWET_STDDEV))+
  labs(fill = "SBS Class")

```